{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Visualization Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Answer business requirement 1: \n",
        "    * As a customer I am interested to understand the patterns from my customer base, so I can better manage churn levels.\n",
        "\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* generate code that answers business requirement 1 and can be used to build Streamlit App\n",
        "\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGT0ZCtwFAFv"
      },
      "source": [
        "# Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcidnQspZztu"
      },
      "source": [
        "! pip install pandas-profiling==2.11.0\n",
        "! pip install plotly==4.14.0\n",
        "! pip install feature-engine==1.0.2\n",
        "\n",
        "# Code for restarting the runtime, that will restart colab session\n",
        "# It is a good practice after you install a package in a colab session\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0QdOnpiUTRC"
      },
      "source": [
        "# Setup GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIifw4yCpZwI"
      },
      "source": [
        "* Go to Edit â†’ Notebook Settings\n",
        "* In the Hardware accelerator menu, selects GPU\n",
        "* note: when you select an option, either GPU, TPU or None, you switch among kernels/sessions\n",
        "\n",
        "---\n",
        "* How to know if I am using the GPU?\n",
        "  * run the code below, if the output is different than '0' or null/nothing, you are using GPU in this session\n",
        "  * Typically the output will be /device:GPU:0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHJJd1XhUTjd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WicMedgXzMgS"
      },
      "source": [
        "# **Connection between: Colab Session and your GitHub Repo**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5Uczzm_zXI4"
      },
      "source": [
        "### Insert your **credentials**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1q2QBwkcIH2"
      },
      "source": [
        "* The variable's content will exist only while the session exists. Once this session terminates, the variable's content will be erased permanently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6jYL7Crh3an"
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "from IPython.display import clear_output \n",
        "\n",
        "print(\"=== Insert your credentials === \\nType in and hit Enter\")\n",
        "os.environ['UserName'] = getpass('GitHub User Name: ')\n",
        "os.environ['UserEmail'] = getpass('GitHub User E-mail: ')\n",
        "os.environ['RepoName'] = getpass('GitHub Repository Name: ')\n",
        "os.environ['UserPwd'] = getpass('GitHub Account Password: ')\n",
        "clear_output()\n",
        "print(\"* Thanks for inserting your credentials!\")\n",
        "print(f\"* You may now Clone your Repo to this Session, \"\n",
        "      f\"then Connect this Session to your Repo.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtMP7Pjvwpm2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPPGQ3xa0dH1"
      },
      "source": [
        "### **Clone** your GitHub Repo to your current Colab session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4V8x_AF1Euv"
      },
      "source": [
        "* So you can have access to your project's files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fOslPfih6Qn"
      },
      "source": [
        "! git clone https://github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "! rm -rf sample_data   # remove content/sample_data folder, since we dont need it for this project\n",
        "\n",
        "import os\n",
        "if os.path.isdir(os.environ['RepoName']):\n",
        "  print(\"\\n\")\n",
        "  %cd /content/{os.environ['RepoName']}\n",
        "  print(f\"\\n\\n* Current session directory is:{os.getcwd()}\")\n",
        "  print(f\"* You may refresh the session folder to access {os.environ['RepoName']} folder.\")\n",
        "else:\n",
        "  print(f\"\\n* The Repo {os.environ['UserName']}/{os.environ['RepoName']} was not cloned.\"\n",
        "        f\" Please check your Credentials: UserName and RepoName\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTydg5Xwqiu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-5uhLCk0lUJ"
      },
      "source": [
        "### **Connect** this Colab session to your GitHub Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra3ns1Tl0_MS"
      },
      "source": [
        "* So if you need, you can push files generated in this session to your Repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRImgZx7h-WY"
      },
      "source": [
        "! git config --global user.email {os.environ['UserEmail']}\n",
        "! git config --global user.name {os.environ['UserName']}\n",
        "! git remote rm origin\n",
        "! git remote add origin https://{os.environ['UserName']}:{os.environ['UserPwd']}@github.com/{os.environ['UserName']}/{os.environ['RepoName']}.git\n",
        "\n",
        "# the logic is: create a temporary file in the sessions, update the repo. Delete this file, update the repo\n",
        "# If it works, it is a signed that the session is connected to the repo.\n",
        "import uuid\n",
        "file_name = \"session_connection_test_\" + str(uuid.uuid4()) # generates a unique file name\n",
        "with open(f\"{file_name}.txt\", \"w\") as file: file.write(\"text\")\n",
        "print(\"=== Testing Session Connectivity to the Repo === \\n\")\n",
        "! git add . ; ! git commit -m {file_name + \"_added_file\"} ; ! git push origin main \n",
        "print(\"\\n\\n\")\n",
        "os.remove(f\"{file_name}.txt\")\n",
        "! git add . ; ! git commit -m {file_name + \"_removed_file\"}; ! git push origin main\n",
        "\n",
        "# delete your Credentials (username and password)\n",
        "os.environ['UserName'] = os.environ['UserPwd'] = os.environ['UserEmail'] = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKKIufOcexSz"
      },
      "source": [
        "* If output above indicates there was a **failure in the authentication**, please insert again your credentials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRwFQLlmwrl9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZcmA1wG8AdC"
      },
      "source": [
        "### **Push** generated/new files from this Session to GitHub repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNJsZ5UeQDG"
      },
      "source": [
        "* Git status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1Nrg1IgeQMD"
      },
      "source": [
        "! git status"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1kUQ0VIoi4c"
      },
      "source": [
        "* Git commit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dafOBor8OoM"
      },
      "source": [
        "CommitMsg = \"added-cleaned-data\"\n",
        "!git add .\n",
        "!git commit -m {CommitMsg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXkyUs70oloW"
      },
      "source": [
        "* Git Push"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0NCb8-L8Vr1"
      },
      "source": [
        "!git push origin main\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2oPUd1K_qCr"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXTuEOt2c3E"
      },
      "source": [
        "# load data\n",
        "# split train test set\n",
        "\n",
        "# create model\n",
        "#fit model, use tensorboard,with hyperparameter opitimization\n",
        "# evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqqga261_w4N"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntzIpcxb3oIE"
      },
      "source": [
        "my_data_dir = '/content/WalkthroughProject01/inputs/datasets/cell_images/cell_images'\n",
        "target_classes = os.listdir(my_data_dir)\n",
        "target_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eucaA9M6qz1"
      },
      "source": [
        "train_path = my_data_dir+'\\\\train\\\\'????"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeOv0tCn3_Y_"
      },
      "source": [
        "for x in target_classes:\n",
        "  print(f\"* There are {len(os.listdir(my_data_dir+'/'+x))} images in class {x}.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMQVJmyC4IX4"
      },
      "source": [
        "para_img = imread(my_data_dir+ '/'+ target_classes[1]+ '/'+ os.listdir(my_data_dir+'/'+target_classes[1])[0])\n",
        "print(para_img.shape)\n",
        "plt.imshow(para_img)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlUjj6Qb4iGJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OptI7pnA6zPZ"
      },
      "source": [
        "image sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaLv-P7Y85CL"
      },
      "source": [
        "my_data_dir+ '/'+ target_classes[1] + '/'+ image_filename # os.listdir(my_data_dir+'/'+target_classes[1])[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00W_ROgJ71a-"
      },
      "source": [
        "dim1,dim2 = [], []\n",
        "for label in target_classes:\n",
        "  for image_filename in os.listdir(my_data_dir+ '/'+ label):\n",
        "    try:\n",
        "      img = imread(my_data_dir+ '/'+ label + '/'+ image_filename)\n",
        "      d1, d2, colors = img.shape\n",
        "      dim1.append(d1)\n",
        "      dim2.append(d2)\n",
        "    except Exception as e:\n",
        "      print(e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG1aHYHT9-2m"
      },
      "source": [
        "fig, axes = plt.subplots()\n",
        "sns.scatterplot(x=dim1, y=dim2, alpha=0.2)\n",
        "dim1_mean = np.array(dim1).mean()\n",
        "dim2_mean = np.array(dim2).mean()\n",
        "axes.axvline(x=dim1_mean,color='#D1349C', linestyle='-')\n",
        "axes.axhline(y=dim2_mean,color='#D1349C', linestyle='-')\n",
        "plt.text(x=np.array(dim1).min(), y=np.array(dim2).max()*0.9,\n",
        "         s=f\"Pixels lenght average: {round(dim1_mean,0)}\\nPixel width average: {round(dim2_mean,)}\", c='r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaWVery3Afa8"
      },
      "source": [
        "image_shape = (133,132,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hidGo-uhBq1L"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMU8_F6ZAfjS"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIkD9esZAhTm"
      },
      "source": [
        "image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees\n",
        "                               width_shift_range=0.10, # Shift the pic width by a max of 5%\n",
        "                               height_shift_range=0.10, # Shift the pic height by a max of 5%\n",
        "                               rescale=1/255, # Rescale the image by normalzing it.\n",
        "                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n",
        "                               zoom_range=0.1, # Zoom in by 10% max\n",
        "                               horizontal_flip=True, # Allo horizontal flipping\n",
        "                               fill_mode='nearest' # Fill in missing pixels with the nearest filled value\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-OV-AtyAhW0"
      },
      "source": [
        "plt.imshow(para_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFJqnauMApW4"
      },
      "source": [
        "plt.imshow(image_gen.random_transform(para_img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz9pduFtBPxR"
      },
      "source": [
        "# image_gen.flow_from_directory(my_data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aw_g3aIBsZG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3em0FUWzBTCF"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Dropouts help reduce overfitting by randomly turning neurons off during training.\n",
        "# Here we say randomly turn off 50% of neurons.\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Last layer, remember its binary so we use sigmoid\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0fnaUSeBTFy"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49bP61QYBTMF"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNemQ_4HChz9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ7o8oJ3B3wE"
      },
      "source": [
        "batch_size = 16\n",
        "train_image_gen = image_gen.flow_from_directory(my_data_dir,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                                color_mode='rgb',\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9EN8Q8BCsLR"
      },
      "source": [
        "train_image_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHD-ggqiB3zV"
      },
      "source": [
        "train_image_gen."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQoAE4uNB34l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTm0tI1VB3-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGDLfdaiB4IH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsBHpBFJ0ZFa"
      },
      "source": [
        "# Pandas profiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncii4qR90aS1"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DceTmVKMzHZV"
      },
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGjuccXJzKFm"
      },
      "source": [
        "For this analysis, we are transforming the categorical variables with One Hot Encoding technique, so we can see which levels tend to affect more Churn Levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLKtmzubuK2Z"
      },
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=df.columns[df.dtypes=='object'].to_list(), drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7e-64OzeP0"
      },
      "source": [
        "We use `.corr()` for `spearman` and `pearson` methods, and investigate the top 10 correlations\n",
        "* We know this command returns a pandas series and the first item is the correlation between Churn and Churn, which happens to be 1, so we exclude that with `[1:]`\n",
        "* We sort values considering the aboslute value, by setting `key=abs`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPn8xl6N_sug"
      },
      "source": [
        "corr_spearman = df_ohe.corr(method='spearman')['Churn'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_spearman"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rIu67nO0LDs"
      },
      "source": [
        "We do the same for `pearson`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uop6Vvk4wrF0"
      },
      "source": [
        "corr_pearson = df_ohe.corr(method='pearson')['Churn'].sort_values(key=abs, ascending=False)[1:].head(10)\n",
        "corr_pearson"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHrTrQYO0px_"
      },
      "source": [
        "For both methods, we notice weak or moderate levels of correlation between Churn and a given variable. \n",
        "* Ideally, we pursue at strong correlation levels or more. However, this is not always possible\n",
        "\n",
        "We will consider the top 7 correlation levels at `df_ohe` and will study the associated variables at `df`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-5y4MY71Nk5"
      },
      "source": [
        "top_n = 5\n",
        "set(corr_pearson[:top_n].index.to_list() + corr_spearman[:top_n].index.to_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vz-wC9e2I-z"
      },
      "source": [
        "Therefore we are studying at df the following variables. We will investigate if:\n",
        "* A churned customern typically has a month to month contract\n",
        "* A churned customer typically has fiber optic\n",
        "* A churned customer typically doesn't have tech support\n",
        "* A churned customer doesn't have online security\n",
        "* A churned customer typically has low tenure levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHKRE6E32NPv"
      },
      "source": [
        "vars_to_study = ['Contract', 'InternetService', 'OnlineSecurity', 'TechSupport', 'tenure']\n",
        "vars_to_study"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV2d12vC0Puq"
      },
      "source": [
        "# EDA on selected variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln0g-NKs__1j"
      },
      "source": [
        "We create a separate DataFrame with `vars_to_study` and `Churn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpIgK8rxAbdR"
      },
      "source": [
        "df_eda = df.filter(vars_to_study + ['Churn'])\n",
        "df_eda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIITMZ-3AGoY"
      },
      "source": [
        "We plot the distribution (numerical and categorical) colored by Churn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ensdFklI3Vbn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "def plot_categorical(df, col, target_var):\n",
        "\n",
        "  plt.figure(figsize=(12, 5))\n",
        "  sns.countplot(data=df, x=col, hue=target_var,order = df[col].value_counts().index)\n",
        "  plt.xticks(rotation=90) \n",
        "  plt.title(f\"{col}\", fontsize=20,y=1.05)        \n",
        "  plt.show()\n",
        "\n",
        "def plot_numerical(df, col, target_var):\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  sns.histplot(data=df, x=col, hue=target_var, kde=True,element=\"step\") \n",
        "  plt.title(f\"{col}\", fontsize=20,y=1.05)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "target_var = 'Churn'\n",
        "for col in df_eda.drop([target_var], axis=1).columns.to_list():\n",
        "  if df_eda[col].dtype == 'object':\n",
        "    plot_categorical(df_eda, col, target_var)\n",
        "    print(\"\\n\\n\")\n",
        "  else:\n",
        "    plot_numerical(df_eda, col, target_var)\n",
        "    print(\"\\n\\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH46EnLZAfYH"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bypwzlCw_Ffg"
      },
      "source": [
        "Create a separate DataFrame and transform `tenure` (numerical) into bins (categorical) for visualizing at `parallel_categories()` plot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMm3x71j_Ego"
      },
      "source": [
        "from feature_engine.discretisation import ArbitraryDiscretiser\n",
        "import numpy as np\n",
        "tenure_map = [-np.Inf, 6, 12, 18, 24, np.Inf]\n",
        "disc = ArbitraryDiscretiser(binning_dict={'tenure': tenure_map},\n",
        "                            return_object=False,\n",
        "                            return_boundaries=False)\n",
        "df_parallel = disc.fit_transform(df_eda)\n",
        "df_parallel.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8SOHbD6QT-L"
      },
      "source": [
        "Create map to replace `tenure` variable with more informative levels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s3W0esgPBng"
      },
      "source": [
        "n_classes = len(tenure_map) - 1\n",
        "classes_ranges = disc.binner_dict_['tenure'][1:-1]\n",
        "\n",
        "LabelsMap = {}\n",
        "for n in range(0,n_classes):\n",
        "  if n == 0:\n",
        "    LabelsMap[n] = f\"<{classes_ranges[0]}\"\n",
        "  elif n == n_classes-1:\n",
        "    LabelsMap[n] = f\"+{classes_ranges[-1]}\"\n",
        "  else:\n",
        "    LabelsMap[n] = f\"{classes_ranges[n-1]} to {classes_ranges[n]}\"\n",
        "\n",
        "LabelsMap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7nvRC9uQhag"
      },
      "source": [
        "Replace using `.replace()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGrZNt6I_i3o"
      },
      "source": [
        "df_parallel['tenure'] = df_parallel['tenure'].replace(LabelsMap)\n",
        "df_parallel.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgYQ30JXQxBR"
      },
      "source": [
        "Creates multi-dimensional categorical data plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpjcTS4XAbgO"
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.parallel_categories(df_parallel, color=\"Churn\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua0-YwyMCtDy"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jkAa1rpCLbY"
      },
      "source": [
        "# Conclusions and Next steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX7YiPhWCNmc"
      },
      "source": [
        "The correlation indications and plots above interpretation converge. \n",
        "* The insights above will be used as reference additional investigations, like: why high churn levels in fiber optic?\n",
        "* But for the present project, it answers business requeriment 1.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q4VCr3-CXLx"
      },
      "source": [
        "Find below how the insights can be used when approaching a prospect that might churn:\n",
        "* If a prospect looks to be churnable, and is not showing openness to our offers we will concede free tech support and online security for 18 months.\n",
        "* We will offer 15% discount for a year when the prospect switch from month to month to year plan. \n",
        "* We will give 5% discount when the prospect switch to an automated payment method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBfDO-QECm4k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}