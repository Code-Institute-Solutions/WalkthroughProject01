{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_file_for_image,_text,_pandas_profile.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python383jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoWVo5csafaS"
      },
      "source": [
        "# Seaborn Lesson, test made for saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fYCxIJfhPwF"
      },
      "source": [
        "## Lesson Learning Outcome"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKAhSxNvhTg0"
      },
      "source": [
        "* **xxx Lesson is made of 5 units.**\n",
        "* By the end of this lesson, you should be able to:\n",
        "  * Lxxx\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndq4Kg-yhxKm"
      },
      "source": [
        "## Unit Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiujW2ORafaX"
      },
      "source": [
        "* xxxx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRr9AthgafaZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXeFM9FuafaY"
      },
      "source": [
        "* Sexxx\n",
        "* **Why do we study xxxxx?**\n",
        "  * Seaborxxx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfTD1ZiMjE53"
      },
      "source": [
        "## Additional Learning Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05-LnxO9jGRN"
      },
      "source": [
        "* We encourage you to:\n",
        "  * Add **code cells and try it out** other possibilities, ie.: play around with parameters values in a function/method, or consider additional function parameters etc.\n",
        "  * Also, **add your own comment** in the cells. It can help you to consolidate the learning. \n",
        "\n",
        "* Notebook Challenge\n",
        "  * At the end of the unit notebook, there is a challenge section.\n",
        "  * **Do the challenge** in the provided cell, then **run the test**.\n",
        "  * Only when the tests for **all challenges are passed**, **click submit button**.\n",
        "\n",
        "* Parameters in given function/method\n",
        "  * As you may expect, a given function in a package may contain multiple parameters. \n",
        "  * Some of them are mandatory to declare; some have pre-defined values; and some are optional. We will cover the most common parameters used/employed at Data Science for a particular function/method. \n",
        "  * However, you may seek additional in the respecive package documentation, where you will find instructions on how to use a given function/method. The studied packages are open source, so this documentation is public.\n",
        "  * **For Seaborn the link is [here](https://seaborn.pydata.org/)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H-A1tntKAwM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hmB6wo1afaZ"
      },
      "source": [
        "## Import Package for Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xb8LsA97DYTm"
      },
      "source": [
        "*  For convention, `Seaborn` is import with the alias `sns`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrgSs9DCafaa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxqw3evSafab"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_1EbUDSXWHo"
      },
      "source": [
        "# Image Exploratory Analyssis \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iFIClUNYoM-"
      },
      "source": [
        "* Image Montage\n",
        "* Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XP0Yc6jEXKO"
      },
      "source": [
        "# df= pd.DataFrame({'Category':['Dog','Cat','Parrot'], 'Amount':[3800,3500,4000]})\n",
        "# df.plot(kind='bar',figsize=(5,5), legend=None)\n",
        "# plt.xticks(plt.xticks()[0], df['Category'].unique())\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERq26SAEKmVW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW-_6F44h0Pk"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc_DENoqh0TL"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpAJE8XziSYj"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "num = 59000\n",
        "\n",
        "print(f\"index = {num}\")\n",
        "print(f\"x_train[{num}] shape: {x_train[num].shape}\")\n",
        "print(f\"target: {y_train[num]}\")\n",
        "plt.imshow(x_train[num],cmap='gray')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBH5ji76kS-l"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jooGowgmNDp"
      },
      "source": [
        "## Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkDZkAcXjL5Y"
      },
      "source": [
        "target_distribution = pd.Series(data=y_train).value_counts().sort_index()\n",
        "target_distribution.plot(kind='bar',figsize=(12,5))\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2kPGhfzupaR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usaoFVRpll3X"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjYizp9EmQ4k"
      },
      "source": [
        "## Image Montage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eNVGt8Nn2ri"
      },
      "source": [
        "import itertools\n",
        "import random\n",
        "\n",
        "def image_montage(X, y,class_to_display, nrows, ncols, figsize=(15,10)):\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  # subset the class you are interested to display\n",
        "  if class_to_display in np.unique(y):\n",
        "    y = y.reshape(-1,1,1)\n",
        "    boolean_mask = np.any(y==class_to_display,axis=1).reshape(-1)\n",
        "    df = X[boolean_mask]\n",
        "\n",
        "  # if that class is not in the data, it shows an montage with all classes\n",
        "  else:\n",
        "    print(\"The class you selected doesn't exist.\")\n",
        "    print(f\"The existing options are: {np.unique(y)}\")\n",
        "    print(\"Find below a montage with all classes\")\n",
        "    df = X\n",
        "\n",
        "  # checks if your montage space is greater than subset size\n",
        "  if nrows * ncols < df.shape[0]:\n",
        "    img_idx = random.sample(range(0, df.shape[0]), nrows * ncols)\n",
        "  else:\n",
        "    print(\n",
        "        f\"Decrease nrows or ncols to create your montage. \\n\"\n",
        "        f\"There are {df.shape[0]} in your subset. \"\n",
        "        f\"You requested a montage with {nrows * ncols} spaces\")\n",
        "    return\n",
        "    \n",
        "  # create list of axes indices based on nrows and ncols\n",
        "  list_rows= range(0,nrows)\n",
        "  list_cols= range(0,ncols)\n",
        "  plot_idx = list(itertools.product(list_rows,list_cols))\n",
        "\n",
        "  # create a Figure and display images\n",
        "  fig, axes = plt.subplots(nrows=nrows,ncols=ncols, figsize=figsize)\n",
        "  for x in range(0,nrows*ncols):\n",
        "    axes[plot_idx[x][0], plot_idx[x][1]].imshow(df[img_idx[x]], cmap='gray')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haCzwaHPq9sF"
      },
      "source": [
        "image_montage(X=x_train, y=y_train,\n",
        "              class_to_display=8,\n",
        "              nrows=3, ncols=3,\n",
        "              figsize=(15,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBFxnl4jmgon"
      },
      "source": [
        "https://towardsdatascience.com/exploratory-data-analysis-ideas-for-image-classification-d3fc6bbfb2d2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz2qH3_2mS6I"
      },
      "source": [
        "## Average Image per Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBS4vmccmTDA"
      },
      "source": [
        "def average_image(X, y, figsize=(12,5)):\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  # what is images have different sizes?\n",
        "\n",
        "\n",
        "  for class_to_display in np.unique(y):\n",
        "    y = y.reshape(-1,1,1)\n",
        "    boolean_mask = np.any(y==class_to_display,axis=1).reshape(-1)\n",
        "    df = X[boolean_mask]\n",
        "    avg_img = np.mean(df, axis = 0)\n",
        "    std_img = np.std(df, axis = 0)\n",
        "    print(f\"==== Class {class_to_display} ====\")\n",
        "    print(avg_img.shape)\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
        "    axes[0].set_title(f\"Average Image for class {class_to_display}\")\n",
        "    axes[0].imshow(avg_img, cmap='gray')\n",
        "    axes[1].set_title(f\"Standard Deviation for class {class_to_display}\")\n",
        "    axes[1].imshow(std_img, cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "  \n",
        "\n",
        "\n",
        "average_image(X=x_train, y=y_train, figsize=(12,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJCPENWmmTKn"
      },
      "source": [
        "## Contrast between 2 Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfIO60NEmTS4"
      },
      "source": [
        "def contrast_between_2_classes(X, y, class_1, class_2, figsize=(12,5)):\n",
        "  sns.set_style(\"white\")\n",
        "\n",
        "  # what is images have different sizes?\n",
        "\n",
        "  if (class_1 in np.unique(y)) & (class_2 in np.unique(y)):\n",
        "     print(\"both are\")\n",
        "  else:\n",
        "    print(f\"The classess {class_1} and {class_2} are not in {np.unique(y)} \")\n",
        "    return\n",
        "\n",
        "  print([class_1,class_1])\n",
        "\n",
        "  # for class_to_display in np.unique(y):\n",
        "  #   y = y.reshape(-1,1,1)\n",
        "  #   boolean_mask = np.any(y==class_to_display,axis=1).reshape(-1)\n",
        "  #   df = X[boolean_mask]\n",
        "  #   avg_img = np.mean(df, axis = 0)\n",
        "  #   std_img = np.std(df, axis = 0)\n",
        "  #   print(f\"==== Class {class_to_display} ====\")\n",
        "  #   print(avg_img.shape)\n",
        "  #   fig, axes = plt.subplots(nrows=1, ncols=2, figsize=figsize)\n",
        "  #   axes[0].set_title(f\"Average Image for class {class_to_display}\")\n",
        "  #   axes[0].imshow(avg_img, cmap='gray')\n",
        "  #   axes[1].set_title(f\"Standard Deviation for class {class_to_display}\")\n",
        "  #   axes[1].imshow(std_img, cmap='gray')\n",
        "  #   plt.show()\n",
        "  #   print(\"\\n\")\n",
        "  \n",
        "\n",
        "\n",
        "contrast_between_2_classes(X=x_train, y=y_train,\n",
        "                           class_1=1, class_2=2,figsize=(12,5))\n",
        "\n",
        "\n",
        "# contrast_mean = norm_mean - pneu_mean\n",
        "# plt.imshow(contrast_mean, cmap='bwr')\n",
        "# plt.title(f'Difference Between Normal & Pneumonia Average')\n",
        "# plt.axis('off')\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdj6c01Zm1l-"
      },
      "source": [
        "## Eigenimages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Wcm9jKlpO0r"
      },
      "source": [
        "https://en.wikipedia.org/wiki/Eigenface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmlSQNmJm5j9"
      },
      "source": [
        "Lastly, we can use a dimension reduction technique such as the principal component analysis (PCA) to visualize the components that describe each class the best. The eigenimages, which is essentially the eigenvectors (components) of PCA of our image matrix, can be reshaped into a matrix and be plotted. Itâ€™s also called eigenfaces as this approach was first used for facial recognition research. Here we will visualize the principal components that describe 70% of variability for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtcIESfwm2RC"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from math import ceil\n",
        "\n",
        "def eigenimages(full_mat, title, n_comp = 0.7, size = (64, 64)):\n",
        "    # fit PCA to describe n_comp * variability in the class\n",
        "    pca = PCA(n_components = n_comp, whiten = True)\n",
        "    pca.fit(full_mat)\n",
        "    print('Number of PC: ', pca.n_components_)\n",
        "    return pca\n",
        "  \n",
        "def plot_pca(pca, size = (64, 64)):\n",
        "    # plot eigenimages in a grid\n",
        "    n = pca.n_components_\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    r = int(n**.5)\n",
        "    c = ceil(n/ r)\n",
        "    for i in range(n):\n",
        "        ax = fig.add_subplot(r, c, i + 1, xticks = [], yticks = [])\n",
        "        ax.imshow(pca.components_[i].reshape(size), \n",
        "                  cmap='Greys_r')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "plot_pca(eigenimages(normal_images, 'NORMAL'))\n",
        "plot_pca(eigenimages(pnemonia_images, 'PNEUMONIA'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMrSz137nApG"
      },
      "source": [
        "we can also look at the fisherfaces, and the correlation matrix across pixels for our exploratory analysis of the image data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZlYvpFfo-fw"
      },
      "source": [
        "## Correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqK4JSKCo_pB"
      },
      "source": [
        "take given class, compute correlation, find correlated pixels\n",
        "plot these pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPzPjdHIpGxI"
      },
      "source": [
        "## Fisherfaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJnvq5WIl_zW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzGKiCB_ngnB"
      },
      "source": [
        "https://towardsdatascience.com/pneumonia-detection-pushing-the-boundaries-of-human-ability-with-deep-learning-ce08dbd0dc20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESEyGEAncdc"
      },
      "source": [
        "## image processing for modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N06artIGniUP"
      },
      "source": [
        "* Pixel Normalization\n",
        "* Data Augmentation\n",
        "* Modeling\n",
        "* Converting from RGB to Grayscale Image\n",
        "* Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSllfwHOne6p"
      },
      "source": [
        "https://towardsdatascience.com/pneumonia-detection-pushing-the-boundaries-of-human-ability-with-deep-learning-ce08dbd0dc20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf_Of_pPeAKp"
      },
      "source": [
        "# Text: WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRkBc__Q_tSM"
      },
      "source": [
        "# https://towardsdatascience.com/simple-wordcloud-in-python-2ae54a9f58e5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgeydN8i488E"
      },
      "source": [
        "! pip install wikipedia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLVgg5DzeAbG"
      },
      "source": [
        "# https://texthero.org/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7w0CTqT47PL"
      },
      "source": [
        "import wikipedia\n",
        "import re\n",
        "# Specify the title of the Wikipedia page\n",
        "wiki = wikipedia.page('Brasil')\n",
        "# Extract the plain text content of the page\n",
        "text = wiki.content\n",
        "# Clean text\n",
        "text = re.sub(r'==.*?==+', '', text)\n",
        "text = text.replace('\\n', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdJMFB9A81e7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3n66hLB82RT"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/maxent-ai/Datasets/master/data/politics18/catchnews_2018.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhYuZOxX9Miu"
      },
      "source": [
        "df['author'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaPs1QT79MlW"
      },
      "source": [
        "text = ' '.join(df.query(\"author == 'Nishant  Chhabra'\")['content'].dropna().tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aaZbW5K9M7e"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM5lNA885Nf_"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k81y6lJT47Rk"
      },
      "source": [
        "# Import package\n",
        "import matplotlib.pyplot as plt\n",
        "# Define a function to plot word cloud\n",
        "def plot_cloud(wordcloud):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    plt.imshow(wordcloud) \n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FntTwedkS61v"
      },
      "source": [
        "! pip show wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSUpSeI247UD"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "wordcloud = WordCloud(width = 800, height = 400, random_state=1,\n",
        "                      background_color='salmon', colormap='Pastel1',\n",
        "                      collocations=False, stopwords = STOPWORDS,).generate(text)\n",
        "\n",
        "plot_cloud(wordcloud)\n",
        "\n",
        "# background_color='white', colormap='Set2'\n",
        "# background_color='navy', colormap='rainbow',"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDU3i0Ej-qeY"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jawAavbOUp1w"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/LawrenceDuan/IMDb-Review-Analysis/master/IMDb_Reviews.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDpo1t3BVdnR"
      },
      "source": [
        "text = ' '.join(df.query(\"sentiment == 1\")['review'].dropna().tolist())\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmOGwgYaYARA"
      },
      "source": [
        "import re\n",
        "text = re.sub(r'==.*?==+', '', text)\n",
        "for x in ['\\n','/><br','<br', 'br', '/><br', '/>']:\n",
        "  text = text.replace(x, '')\n",
        "\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWwBHwguVqdI"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "wordcloud = WordCloud(width = 800, height = 400, random_state=1,\n",
        "                       background_color='navy', colormap='rainbow',\n",
        "                      # background_color='salmon', colormap='Pastel1',\n",
        "                      collocations=False, stopwords = STOPWORDS,).generate(text)\n",
        "\n",
        "plot_cloud(wordcloud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR3LHQSaWAfI"
      },
      "source": [
        "text = ' '.join(df.query(\"sentiment == 0\")['review'].dropna().tolist())\n",
        "\n",
        "import re\n",
        "text = re.sub(r'==.*?==+', '', text)\n",
        "for x in ['\\n','/><br','<br', 'br', '/><br', '/>']:\n",
        "  text = text.replace(x, '')\n",
        "\n",
        "text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJniBQ0Dioo3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNPNppQkV-10"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "wordcloud = WordCloud(width = 800, height = 400, random_state=1,\n",
        "                      background_color='salmon', colormap='Pastel1',\n",
        "                      collocations=False, stopwords = STOPWORDS,).generate(text)\n",
        "\n",
        "plot_cloud(wordcloud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9duNf40oeBjt"
      },
      "source": [
        "# Quick EDA: Pandas Profiling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucKq1oIcAwYW"
      },
      "source": [
        "# https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/\n",
        "# https://towardsdatascience.com/pandas-profiling-a-powerful-exploratory-data-analysis-tool-9c245079be4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZV4RF2yAccw"
      },
      "source": [
        "automated dashboard for quick eda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfe1cn0JeB7g"
      },
      "source": [
        "! pip install pandas-profiling==2.11.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feqp2T3cKTaH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9LLZTeNAj8S"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1)\n",
        "df = pd.DataFrame(data={\"Date\":pd.date_range(start='01/01/2019', periods=300, freq='D'),\n",
        "                        \"Numerical\": np.random.randn(300),\n",
        "                        \"Categorical\": np.random.choice('A B C D E F G'.split(\" \"),size=300),\n",
        "                        \"Boolean\": np.random.choice([True,True,False],size=300)\n",
        "                        })\n",
        "\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uNUC8YbAkBj"
      },
      "source": [
        "think about potential datasets and what to show on them\n",
        "numerical, categorical, date\n",
        "missing data, duplicates\n",
        "correlations, scatter plot\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwvw_Y1pAiFH"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df, minimal=True)\n",
        "profile.to_notebook_iframe()\n",
        "\n",
        "# report = pp.ProfileReport(df, lazy=False, dark_mode=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNiH65_fCK1c"
      },
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "prof = ProfileReport(df)\n",
        "prof.to_file(output_file='output.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL5i18AhCNcR"
      },
      "source": [
        "A big disadvantage of pandas profiling is its use with large datasets. With the increase in the size of the data the time to generate the report also increases a lot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8uORPX_CPx8"
      },
      "source": [
        "profile = ProfileReport(df, minimal=True)\n",
        "profile.to_file(output_file=\"output_min.html\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}